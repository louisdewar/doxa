use std::env;

use opentelemetry::{
    global, runtime::TokioCurrentThread, sdk::propagation::TraceContextPropagator,
};
use tracing_subscriber::layer::SubscriberExt;
use tracing_subscriber::{filter::LevelFilter, EnvFilter, Layer, Registry};

pub fn init_telemetry() {
    let app_name = "doxa_main_server";

    // Start a new Jaeger trace pipeline.
    // Spans are exported in batch - recommended setup for a production application.
    global::set_text_map_propagator(TraceContextPropagator::new());

    let jaeger_endpoint =
        env::var("DOXA_TELEMETRY_ENDPOINT").unwrap_or_else(|_| "localhost:6831".into());

    let tracer = opentelemetry_jaeger::new_pipeline()
        .with_agent_endpoint(jaeger_endpoint)
        .with_service_name(app_name)
        .install_batch(TokioCurrentThread)
        .expect("Failed to install OpenTelemetry tracer.");

    // Filter based on level - trace, debug, info, warn, error
    // Tunable via `RUST_LOG` env variable
    let env_filter = EnvFilter::try_from_default_env().unwrap_or_else(|_| EnvFilter::new("info"));
    // Create a `tracing` layer using the Jaeger tracer
    let telemetry = tracing_opentelemetry::layer().with_tracer(tracer);

    let formatting_layer = tracing_subscriber::fmt::Layer::new()
        .pretty()
        .with_filter(LevelFilter::INFO);

    // Create a `tracing` layer to emit spans as structured logs to stdout
    //let formatting_layer = BunyanFormattingLayer::new(app_name.into(), std::io::stdout);
    // Combined them all together in a `tracing` subscriber
    let subscriber = Registry::default()
        .with(env_filter)
        .with(telemetry)
        .with(formatting_layer);
    // .with(JsonStorageLayer)
    // .with(formatting_layer);
    tracing::subscriber::set_global_default(subscriber)
        .expect("Failed to install `tracing` subscriber.")
}
